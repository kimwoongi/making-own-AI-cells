{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. 나만의 이미지 분류기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoongi/making-own-AI-cells/blob/master/4.%20%EB%82%98%EB%A7%8C%EC%9D%98%20%EC%9D%B4%EB%AF%B8%EC%A7%80%20%EB%B6%84%EB%A5%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MJvVnvirY-xa"
      },
      "cell_type": "markdown",
      "source": [
        "# 나만의 이미지 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 설정 정의"
      ],
      "metadata": {
        "id": "2i3kmToP8dkh"
      }
    },
    {
      "metadata": {
        "id": "JI6I_EpJfxTN"
      },
      "cell_type": "code",
      "source": [
        "index2name = {\n",
        "    0: '마카롱',\n",
        "    1: '티라미수',\n",
        "    2: '타르트'\n",
        "}\n",
        "\n",
        "몇번학습 = 100\n",
        "학습률 = 1e-7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 구글 드라이브 연동"
      ],
      "metadata": {
        "id": "HVTVOFsa8i48"
      }
    },
    {
      "metadata": {
        "id": "P6PZeQhLc_cJ",
        "outputId": "e1e78e04-dc94-44f9-c455-4bf44a2001c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "Grj6OuYN8qyt"
      }
    },
    {
      "metadata": {
        "id": "NRcSmDxzfLjY",
        "outputId": "bad20d50-dfdd-4cf7-89a1-d98b7cce0f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt   \n",
        "\n",
        "train_path = './gdrive/My Drive/Colab Notebooks/myai/train/'\n",
        "test_path = './gdrive/My Drive/Colab Notebooks/myai/test/'\n",
        "train_files = os.listdir(train_path)\n",
        "test_files = os.listdir(test_path)\n",
        "\n",
        "x = [cv2.imread(train_path + file) for file in train_files]\n",
        "x = [cv2.cvtColor(each, cv2.COLOR_BGR2RGB) / 255 for each in x]\n",
        "x = np.asarray([cv2.resize(each, (32, 32), interpolation=cv2.INTER_CUBIC) for each in x])\n",
        "\n",
        "x_test = [cv2.imread(test_path + file) for file in test_files]\n",
        "x_test = [cv2.cvtColor(each, cv2.COLOR_BGR2RGB) / 255for each in x_test]\n",
        "x_test = np.asarray([cv2.resize(each, (32, 32), interpolation=cv2.INTER_CUBIC) for each in x_test])\n",
        "\n",
        "y = [int(file.split('_')[0]) for file in train_files] \n",
        "y_test = [int(file.split('_')[0]) for file in test_files] \n",
        "num_classes = len(index2name)\n",
        "eye = np.eye(num_classes)\n",
        "y = np.asarray([eye[each] for each in y])\n",
        "y_test = np.asarray([eye[each] for each in y_test])\n",
        "\n",
        "print('num_classes:', num_classes)\n",
        "print('x_shape:', x.shape)\n",
        "print('y_shape:', y.shape)\n",
        "\n",
        "i = 0\n",
        "plt.imshow(x[i])                                     # i번째 데이터를 이미지로 보이기\n",
        "plt.show()\n",
        "print(f'{i}번째 데이터 : {index2name[y[i][0]]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes: 3\n",
            "x_shape: (30, 32, 32, 3)\n",
            "y_shape: (30, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번째 데이터 : 티라미수\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Cu9Rlc17Wfiz"
      },
      "cell_type": "code",
      "source": [
        "# ls './gdrive/My Drive/Colab Notebooks/myai/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "dir(optimizers)\n",
        "dir(optimizers.gradient_descent_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW1ZLwBU-dnY",
        "outputId": "9b241fbb-becf-433d-dbac-0dad427c4286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SGD',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'keras_export',\n",
              " 'optimizer_v2',\n",
              " 'tf']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 모델"
      ],
      "metadata": {
        "id": "9FGpxX2b81wG"
      }
    },
    {
      "metadata": {
        "id": "JGO805Igq4v8",
        "outputId": "0f5e5e3a-4a00-44f1-f529-5fff3a310a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Flatten, Dense\n",
        "from keras.optimizers import adam_v2, gradient_descent_v2\n",
        "\n",
        "act = 'tanh'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, 3, padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(64, 3, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(act))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# adam = adam_v2.Adam(lr=몇번학습)\n",
        "# sgd = gradient_descent_v2.SGD(lr=몇번학습)\n",
        "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2, 2, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,993,731\n",
            "Trainable params: 14,986,307\n",
            "Non-trainable params: 7,424\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 학습"
      ],
      "metadata": {
        "id": "Bgh0IJvP84eE"
      }
    },
    {
      "metadata": {
        "id": "3qbxeTYUf32l",
        "outputId": "b4a32573-b9de-4abe-caa9-2fa1fc439407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x, y, epochs=몇번학습, validation_data = (x_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.3277 - accuracy: 0.4000 - val_loss: 1.0683 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.3023 - accuracy: 0.8333 - val_loss: 2.0492 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 5.7003 - accuracy: 0.3667 - val_loss: 3.3626 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.7476 - accuracy: 0.3333 - val_loss: 4.2386 - val_accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 4.3396 - accuracy: 0.5000 - val_loss: 1.5472 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.3982 - accuracy: 0.6000 - val_loss: 2.1041 - val_accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.6767 - accuracy: 0.7333 - val_loss: 2.4865 - val_accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.5460 - accuracy: 0.8667 - val_loss: 2.2144 - val_accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.4661 - accuracy: 0.8000 - val_loss: 1.7199 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.3957 - accuracy: 0.7667 - val_loss: 1.4597 - val_accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.3420 - accuracy: 0.9000 - val_loss: 1.3011 - val_accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.2700 - accuracy: 0.9333 - val_loss: 1.2561 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1883 - accuracy: 0.9333 - val_loss: 1.5114 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1504 - accuracy: 0.9667 - val_loss: 2.0434 - val_accuracy: 0.3333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1393 - accuracy: 0.9667 - val_loss: 2.5900 - val_accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1289 - accuracy: 0.9667 - val_loss: 3.0004 - val_accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.1116 - accuracy: 0.9667 - val_loss: 3.2075 - val_accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0680 - accuracy: 0.9667 - val_loss: 3.2148 - val_accuracy: 0.3333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.1611 - val_accuracy: 0.3333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 3.1019 - val_accuracy: 0.3333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 3.1556 - val_accuracy: 0.3333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 3.4363 - val_accuracy: 0.3333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.7766 - val_accuracy: 0.3333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.0825 - val_accuracy: 0.3333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.3441 - val_accuracy: 0.3333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.5620 - val_accuracy: 0.3333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7422 - val_accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.8903 - val_accuracy: 0.3333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.0119 - val_accuracy: 0.3333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.1126 - val_accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.1959 - val_accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.2634 - val_accuracy: 0.3333\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.3173 - val_accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.3567 - val_accuracy: 0.3333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.3788 - val_accuracy: 0.3333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.3840 - val_accuracy: 0.3333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 9.7213e-04 - accuracy: 1.0000 - val_loss: 5.3701 - val_accuracy: 0.3333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 8.8586e-04 - accuracy: 1.0000 - val_loss: 5.3348 - val_accuracy: 0.3333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 7.9971e-04 - accuracy: 1.0000 - val_loss: 5.2710 - val_accuracy: 0.3333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 7.1901e-04 - accuracy: 1.0000 - val_loss: 5.1794 - val_accuracy: 0.3333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 6.4705e-04 - accuracy: 1.0000 - val_loss: 5.0668 - val_accuracy: 0.3333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 5.8505e-04 - accuracy: 1.0000 - val_loss: 4.9219 - val_accuracy: 0.3333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 5.3315e-04 - accuracy: 1.0000 - val_loss: 4.7531 - val_accuracy: 0.3333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 4.9007e-04 - accuracy: 1.0000 - val_loss: 4.5734 - val_accuracy: 0.3333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 4.5446e-04 - accuracy: 1.0000 - val_loss: 4.4104 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 4.2505e-04 - accuracy: 1.0000 - val_loss: 4.2709 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 4.0055e-04 - accuracy: 1.0000 - val_loss: 4.1363 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 3.8012e-04 - accuracy: 1.0000 - val_loss: 3.9884 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.6291e-04 - accuracy: 1.0000 - val_loss: 3.8238 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 3.4824e-04 - accuracy: 1.0000 - val_loss: 3.7111 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.3553e-04 - accuracy: 1.0000 - val_loss: 3.7375 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.2428e-04 - accuracy: 1.0000 - val_loss: 3.8197 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 3.1411e-04 - accuracy: 1.0000 - val_loss: 3.8631 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 3.0485e-04 - accuracy: 1.0000 - val_loss: 3.8532 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.9627e-04 - accuracy: 1.0000 - val_loss: 3.7839 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.8825e-04 - accuracy: 1.0000 - val_loss: 3.6708 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.8066e-04 - accuracy: 1.0000 - val_loss: 3.5107 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.7348e-04 - accuracy: 1.0000 - val_loss: 3.2897 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.6661e-04 - accuracy: 1.0000 - val_loss: 3.0225 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.6009e-04 - accuracy: 1.0000 - val_loss: 2.7100 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.5395e-04 - accuracy: 1.0000 - val_loss: 2.3422 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.4799e-04 - accuracy: 1.0000 - val_loss: 1.9074 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.4229e-04 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3683e-04 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3161e-04 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2660e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2179e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.1715e-04 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.1270e-04 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.0841e-04 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.0432e-04 - accuracy: 1.0000 - val_loss: 0.9172 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.0039e-04 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.9661e-04 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.9298e-04 - accuracy: 1.0000 - val_loss: 1.2841 - val_accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.8952e-04 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.8619e-04 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.8333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.8301e-04 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.8333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.7996e-04 - accuracy: 1.0000 - val_loss: 1.6422 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.7702e-04 - accuracy: 1.0000 - val_loss: 1.7093 - val_accuracy: 0.8333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.7423e-04 - accuracy: 1.0000 - val_loss: 1.7659 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.7154e-04 - accuracy: 1.0000 - val_loss: 1.8146 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6896e-04 - accuracy: 1.0000 - val_loss: 1.8577 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6647e-04 - accuracy: 1.0000 - val_loss: 1.8965 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6410e-04 - accuracy: 1.0000 - val_loss: 1.9335 - val_accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.6179e-04 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.5961e-04 - accuracy: 1.0000 - val_loss: 2.0009 - val_accuracy: 0.8333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.5747e-04 - accuracy: 1.0000 - val_loss: 2.0298 - val_accuracy: 0.8333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.5544e-04 - accuracy: 1.0000 - val_loss: 2.0536 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.5347e-04 - accuracy: 1.0000 - val_loss: 2.0719 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.5157e-04 - accuracy: 1.0000 - val_loss: 2.0876 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.4975e-04 - accuracy: 1.0000 - val_loss: 2.1033 - val_accuracy: 0.8333\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.4797e-04 - accuracy: 1.0000 - val_loss: 2.1178 - val_accuracy: 0.8333\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.4624e-04 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.4457e-04 - accuracy: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 1.4297e-04 - accuracy: 1.0000 - val_loss: 2.1474 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.4140e-04 - accuracy: 1.0000 - val_loss: 2.1543 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.3989e-04 - accuracy: 1.0000 - val_loss: 2.1604 - val_accuracy: 0.8333\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.3840e-04 - accuracy: 1.0000 - val_loss: 2.1647 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.3695e-04 - accuracy: 1.0000 - val_loss: 2.1672 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.3556e-04 - accuracy: 1.0000 - val_loss: 2.1681 - val_accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 예측"
      ],
      "metadata": {
        "id": "xV0E95kp86z6"
      }
    },
    {
      "metadata": {
        "id": "Vy1XXqBShs4_",
        "outputId": "ea9f85bc-8d33-4690-ae6f-9184204954fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred2 = np.argmax(y_pred, axis=1)\n",
        "y_test2 = np.argmax(y_test, axis=1)\n",
        "\n",
        "y_pred_names = [index2name[y_pred2[i]] for i in range(len(y_pred2))]\n",
        "y_test_names = [index2name[y_test2[i]] for i in range(len(y_test2))]\n",
        "\n",
        "count = 0\n",
        "total = len(y_test_names)\n",
        "for i, (y_pred_name, y_test_name) in enumerate(zip(y_pred_names, y_test_names)):\n",
        "  if y_pred_name == y_test_name:\n",
        "    count += 1\n",
        "accuracy = count / total * 100\n",
        "\n",
        "print('정답들:', y_test_names)\n",
        "print('예측들:', y_pred_names)\n",
        "print('정확도:', accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답들: ['티라미수', '마카롱', '티라미수', '마카롱', '타르트', '타르트']\n",
            "예측들: ['티라미수', '타르트', '티라미수', '마카롱', '타르트', '타르트']\n",
            "정확도: 83.33333333333334\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SdTsNzQLdYEd",
        "outputId": "756e39d8-e446-4c11-adb2-96eccd99579d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 4\n",
        "image = x_test\n",
        "label = y_pred_names\n",
        "\n",
        "print(label[i])\n",
        "plt.imshow(image[i])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타르트\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}